{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train')\n",
    "X_test = pd.read_csv('X_test')\n",
    "y_train = pd.read_csv('y_train')\n",
    "y_test = pd.read_csv('y_test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multipleLinearRegressor(X_train, X_test, y_train, y_test):\n",
    "    slr = LinearRegression()\n",
    "    slr.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = slr.predict(X_train)\n",
    "    print('Multiple Linear Regression R2: {}'.format(slr.score(X_train, y_train)))\n",
    "    print('Multiple Linear Regression MSE: {}'.format(mean_squared_error(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = slr.predict(X_test)\n",
    "    print('Multiple Linear Regression R2: {}'.format(slr.score(X_test, y_test)))\n",
    "    print('Multiple Linear Regression MSE: {}'.format(mean_squared_error(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Simple Linear Regression R2: 0.6682823372108286\n",
      "Simple Linear Regression MSE: 332550167.96296227\n",
      "Test set\n",
      "Simple Linear Regression R2: 0.6674402655508858\n",
      "Simple Linear Regression MSE: 290766593.0625662\n"
     ]
    }
   ],
   "source": [
    "run_multipleLinearRegressor(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lassoRegressor(X_train, X_test, y_train, y_test):\n",
    "    lr = Lasso()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = lr.predict(X_train)\n",
    "    print('Simple Linear Regression R2: {}'.format(lr.score(X_train, y_train)))\n",
    "    print('Simple Linear Regression MSE: {}'.format(mean_squared_error(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = lr.predict(X_test)\n",
    "    print('Simple Linear Regression R2: {}'.format(lr.score(X_test, y_test)))\n",
    "    print('Simple Linear Regression MSE: {}'.format(mean_squared_error(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Simple Linear Regression R2: 0.6682821104364218\n",
      "Simple Linear Regression MSE: 332550395.30650026\n",
      "Test set\n",
      "Simple Linear Regression R2: 0.6675021644041192\n",
      "Simple Linear Regression MSE: 290712473.1051427\n"
     ]
    }
   ],
   "source": [
    "run_lassoRegressor(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nearestNeighbors(X_train, X_test, y_train, y_test):\n",
    "    neigh = KNeighborsRegressor(n_neighbors=50)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = neigh.predict(X_train)\n",
    "    print('Nearest Neighbors Regression R2: {}'.format(neigh.score(X_train, y_train)))\n",
    "    print('Nearest Neighbors Regression MSE: {}'.format(mean_squared_error(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = neigh.predict(X_test)\n",
    "    print('Nearest Neighbors Regression R2: {}'.format(neigh.score(X_test, y_test)))\n",
    "    print('Nearest Neighbors Regression MSE: {}'.format(mean_squared_error(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Simple Linear Regression R2: 0.5674981115540114\n",
      "Simple Linear Regression MSE: 433587329.77213967\n",
      "Test set\n",
      "Simple Linear Regression R2: 0.5588932563108957\n",
      "Simple Linear Regression MSE: 385672382.29205626\n"
     ]
    }
   ],
   "source": [
    "run_nearestNeighbors(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decisionTree(X_train, X_test, y_train, y_test):\n",
    "    dt = DecisionTreeRegressor()\n",
    "    dt.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = dt.predict(X_train)\n",
    "    print('Decision Tree R2: {}'.format(dt.score(X_train, y_train)))\n",
    "    print('Decision Tree MSE: {}'.format(mean_squared_error(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = dt.predict(X_test)\n",
    "    print('Decision Tree R2: {}'.format(dt.score(X_test, y_test)))\n",
    "    print('Decision Tree MSE: {}'.format(mean_squared_error(y_test, pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Decision Tree R2: 0.9999999895392025\n",
      "Decision Tree MSE: 10.487050739957716\n",
      "Test set\n",
      "Decision Tree R2: 0.34668806046803224\n",
      "Decision Tree MSE: 571209521.740444\n"
     ]
    }
   ],
   "source": [
    "run_decisionTree(X_train,\n",
    "        X_test,\n",
    "        y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = rf.predict(X_train)\n",
    "    print('Random Forests R2: {}'.format(r2_score(y_train, pred)))\n",
    "    print('Random Forests MSE: {}'.format(mean_squared_error(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict(X_test)\n",
    "    print('Random Forests R2: {}'.format(r2_score(y_test, pred)))\n",
    "    print('Random Forests MSE: {}'.format(mean_squared_error(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests R2: 0.8123712843455874\n",
      "Random Forests MSE: 188099603.68377063\n",
      "Test set\n",
      "Random Forests R2: 0.7417169755753901\n",
      "Random Forests MSE: 225824317.49364617\n"
     ]
    }
   ],
   "source": [
    "run_randomForests(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradientboosting(X_train, X_test, y_train, y_test):\n",
    "    gb = GradientBoostingRegressor(n_estimators=100,random_state=0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print('Train set')\n",
    "    pred = gb.predict(X_train)\n",
    "    print('Gradient Boosting R2: {}'.format(r2_score(y_train, pred)))\n",
    "    print('Gradient Boosting MSE: {}'.format(mean_squared_error(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = gb.predict(X_test)\n",
    "    print('Gradient Boosting R2: {}'.format(r2_score(y_test, pred)))\n",
    "    print('Gradient Boosting MSE: {}'.format(mean_squared_error(y_test, pred)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests R2: 0.9284394227452683\n",
      "Random Forests MSE: 71740171.40206507\n",
      "Test set\n",
      "Random Forests R2: 0.7816665543994454\n",
      "Random Forests MSE: 190895245.4332629\n"
     ]
    }
   ],
   "source": [
    "run_gradientboosting(X_train,\n",
    "                  X_test,\n",
    "                  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters in the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 16.4min finished\n",
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 70,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1400}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2: 0.7417169755753901\n",
      "MSE: 225824317.49364617\n",
      "Model Performance\n",
      "R2: 0.7910890511885029\n",
      "MSE: 182656884.00314087\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    pred = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print('R2: {}'.format(r2_score(test_labels, pred)))\n",
    "    print('MSE: {}'.format(mean_squared_error(test_labels, pred)))\n",
    "    \n",
    "    return \n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators=200, random_state=39, max_depth=4)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "     'max_depth': [60, 70, 80],\n",
    "     'max_features': ['auto'],\n",
    "     'min_samples_leaf': [1,2],\n",
    "     'min_samples_split': [2, 3],\n",
    "     'n_estimators': [1300, 1400, 1500]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 10.4min finished\n",
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 1400}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2: 0.7417169755753901\n",
      "MSE: 225824317.49364617\n",
      "Random Search\n",
      "Model Performance\n",
      "R2: 0.7910890511885029\n",
      "MSE: 182656884.00314087\n",
      "Grid Search\n",
      "Model Performance\n",
      "R2: 0.7930482714981615\n",
      "MSE: 180943881.02807504\n"
     ]
    }
   ],
   "source": [
    "print('Original')\n",
    "base_model = RandomForestRegressor(n_estimators=200, random_state=39, max_depth=4)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "print('Random Search')\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print('Grid Search')\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters in the Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [2, 6, 11, 16, 21, 26, 30, 35, 40, 45, 50, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'loss': ['ls', 'lad']}\n"
     ]
    }
   ],
   "source": [
    "# Loss function to be optimized\n",
    "loss=['ls', 'lad']\n",
    "# Number of boosting stages to perform\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 50, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'loss': loss}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 100.2min finished\n",
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_...\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'loss': ['ls', 'lad'],\n",
       "                                        'max_depth': [2, 6, 11, 16, 21, 26, 30,\n",
       "                                                      35, 40, 45, 50, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 311, 522, 733,\n",
       "                                                         944, 1155, 1366, 1577,\n",
       "                                                         1788, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "gb = GradientBoostingRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "gb_random = RandomizedSearchCV(estimator = gb, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "gb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'lad',\n",
       " 'max_depth': 45,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 2000}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audreytang/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2: 0.7816665543994454\n",
      "MSE: 190895245.4332629\n",
      "Model Performance\n",
      "R2: 0.7681318740901667\n",
      "MSE: 202729007.83459216\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    pred = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print('R2: {}'.format(r2_score(test_labels, pred)))\n",
    "    print('MSE: {}'.format(mean_squared_error(test_labels, pred)))\n",
    "    \n",
    "    return \n",
    "\n",
    "base_model = GradientBoostingRegressor(n_estimators=100,random_state=0)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = gb_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "     'max_depth': [95, 100, 105],\n",
    "     'max_features': ['sqrt'],\n",
    "     'min_samples_leaf': [1,2],\n",
    "     'min_samples_split': [5, 6],\n",
    "     'n_estimators': [1980, 2000, 2020]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = GradientBoostingRegressor(n_estimators=100,random_state=0)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = gb_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
